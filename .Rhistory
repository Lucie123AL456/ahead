ahead::ridge2f(fpp::insurance)$mean
library(ahead)
ahead::ridge2f(fpp::insurance)$mean
ahead::ridge2f(fpp::insurance)$mean
library(ahead)
ahead::ridge2f(fpp::insurance)$mean
microbenchmark::microbenchmark(ahead::ridge2f(fpp::insurance)$mean)
microbenchmark::microbenchmark(ahead::ridge2f(fpp::insurance)$mean)
devtools::test()
set.seed(123)
x <- ts(matrix(rnorm(100), ncol = 5))
res1 <- ahead::ridge2f(x)
res2 <- ahead::ridge2f(x, type_pi = "bootstrap", B=5)
res1$mean[1, 1]
res2$mean[1, 1]
res2$lower[1, 1]
res1$lower[1, 1]
library(ahead)
set.seed(123)
x <- ts(matrix(rnorm(100), ncol = 5))
res1 <- ahead::ridge2f(x)
res2 <- ahead::ridge2f(x, type_pi = "bootstrap", B=5)
res1$mean[1, 1]
res2$mean[1, 1]
res1$lower[1, 1]
res2$lower[1, 1]
devtools::test()
pkgdown::build_site()
EuStockMarkets
res <- ahead::ridge2f(EuStockMarkets, h=100, type_pi = "bootstrap", B=500)
?plot.mts
?ahead::ridge2f
plot(res, "DAX")
plot(res, "CAC")
plot(res, "SMI")
plot(res, "FTSE")
dim(EuStockMarkets)
par(mfrow=c(2, 2))
plot(res, "CAC")
plot(res, "FTSE")
plot(res, "SMI")
plot(res, "DAX")
res <- ahead::ridge2f(EuStockMarkets, h=100, type_pi = "bootstrap", B=1000)
par(mfrow=c(2, 2))
plot(res, "SMI")
plot(res, "DAX")
plot(res, "FTSE")
plot(res, "CAC")
res <- ahead::ridge2f(fpp::usconsumption, type_pi = "bootstrap", h=10, B=1000)
plot(res, "consumption")
plot(res, "income")
?lm.fit
n <- 7 ; p <- 2
X <- matrix(rnorm(n * p), n, p) # no intercept!
colSums(X)
X
colMeans(X)
apply(X, 2, median)
X[nrow(X),]
X
x <- apply(X, 2, median)
x
replicate(5, x)
t(replicate(5, x))
?replicate
library(ahead)
?switch
require(stats)
centre <- function(x, type) {
switch(type,
mean = mean(x),
median = median(x),
trimmed = mean(x, trim = .1))
}
x <- rcauchy(10)
centre(x, "mean")
centre(x, mean)
sqrt(17.830657894736845)
forecast::meanf
?forecast::meanf
nile.fcast <- forecast::meanf(Nile, h=10, bootstrap=TRUE, npaths=100)
nile.fcast
nile.fcast$model$bootstrap
plot(nile.fcast)
forecast::meanf
?sweep
ggplot2::economics
forecast::meanf
level <- 95
1 - (1 - level / 100) / 2
(1 - level / 100) / 2
paste0("basic(", method, ")"
paste0("basic(", method, ")")
paste0("basic(", "mean", ")")
vector("list", length = 3)
sample.int(n = 10, size = 5, replace = TRUE)
sample.int(n = 10, size = 5, replace = TRUE)
sample.int(n = 10, size = 5, replace = TRUE)
library(ahead)
ahead::basicf(fpp::usconsumption)$mean
ahead::basicf(fpp::usconsumption)$lower
ahead::basicf(fpp::usconsumption)$upper
res <- ahead::basicf(fpp::usconsumption)
plot(res, "income")
plot(res, "consumption")
res <- ahead::basicf(fpp::usconsumption, h=10, B=1000)
plot(res, "consumption")
plot(res, "income")
res <- ahead::basicf(fpp::usconsumption, h=10, B=1000, method = "median")
plot(res, "consumption")
plot(res, "income")
res$sims[[1]]
length(res$sims)
res$sims[[2]]
head(fpp::usconsumption)
plot(ahead::meanf(fpp::usconsumption[,2], h=10))
plot(forecast::meanf(fpp::usconsumption[,2], h=10))
forecast::meanf(fpp::usconsumption[,2], h=10)
ahead::basicf(fpp::usconsumption, h=10)
ahead::basicf(fpp::usconsumption, h=10)$mean
library(ahead)
ahead::basicf(fpp::usconsumption, h=10)$mean
forecast::meanf(fpp::usconsumption[,2], h=10)
ahead::basicf(fpp::usconsumption, h=10)$lower
res <- ahead::basicf(fpp::usconsumption, h=10, B=1000)
plot(res, "income")
res <- ahead::basicf(fpp::usconsumption, h=10, B=500)
plot(res, "income")
res <- ahead::basicf(fpp::usconsumption, h=10, B=500, method = "median")
plot(res, "income")
res <- ahead::basicf(fpp::usconsumption, h=10, B=500, method = "rw")
plot(res, "income")
mat <- matrix(rnorm(280*100), nrow = 280, ncol = 100)
microbenchmark::microbenchmark(ahead::basicf(mat))
microbenchmark::microbenchmark(ahead::basicf(mat, B=250))
microbenchmark::microbenchmark(ahead::basicf(mat, B=500))
library(ahead)
res <- ahead::basicf(fpp::usconsumption, h=10, B=500, method = "rw")
plot(res, "income")
res <- ahead::basicf(fpp::usconsumption, h=10, B=250, method = "rw")
plot(res, "income")
res <- ahead::basicf(fpp::usconsumption, h=10, B=1000, method = "rw")
plot(res, "income")
library(ahead)
res <- ahead::basicf(fpp::insurance)
library(ahead)
res <- ahead::basicf(fpp::insurance)
plot(res, "TV.advert")
plot(res, "Quotes")
res <- ahead::basicf(fpp::usconsumption)
plot(res, "income")
plot(res, "cons")
plot(res, "consumption")
res <- ahead::basicf(fpp::usconsumption, type_pi = "boot")
plot(res, "consumption")
res <- ahead::basicf(fpp::usconsumption, type_pi = "boot", B=250)
plot(res, "consumption")
res <- ahead::basicf(fpp::usconsumption, type_pi = "boot", B=500)
plot(res, "consumption")
res <- ahead::basicf(ggplot2::economics[,2:6], type_pi = "boot", B=100)
res$mean
plot(res, "pce")
plot(res, "psavert")
plot(res, "uempmed")
plot(res, "unemploy")
91/90-1
85/91-1
res <- ahead::basicf(fpp::insurance)
plot(res, "insurance")
plot(res, "TV.advert")
plot(res, "Quotes")
res <- ahead::basicf(fpp::insurance)
par(mfrow=c(1, 2))
plot(res, "TV.advert")
plot(res, "Quotes")
res <- ahead::basicf(fpp::insurance, method="rw")
par(mfrow=c(1, 2))
plot(res, "TV.advert")
plot(res, "Quotes")
res <- ahead::basicf(fpp::insurance)
par(mfrow=c(1, 2))
plot(res, "TV.advert")
plot(res, "Quotes")
res <- ahead::basicf(fpp::insurance, type_pi = "bootstrap")
par(mfrow=c(1, 2))
plot(res, "TV.advert")
plot(res, "Quotes")
res <- ahead::basicf(fpp::insurance, type_pi = "bootstrap", method = "rw")
par(mfrow=c(1, 2))
plot(res, "TV.advert")
plot(res, "Quotes")
library(ahead)
res <- ahead::basicf(fpp::insurance, h=10)
par(mfrow=c(1, 2))
plot(res, "TV.advert")
plot(res, "Quotes")
res <- ahead::basicf(fpp::insurance, method="rw", h=10)
par(mfrow=c(1, 2))
plot(res, "TV.advert")
plot(res, "Quotes")
res <- ahead::basicf(fpp::insurance, method="rw", h=10, type_pi = "bootstrap")
par(mfrow=c(1, 2))
plot(res, "TV.advert")
plot(res, "Quotes")
res <- ahead::basicf(fpp::insurance, method="median", h=10, type_pi = "bootstrap")
par(mfrow=c(1, 2))
plot(res, "TV.advert")
plot(res, "Quotes")
res <- ahead::basicf(fpp::insurance, method="rw", h=10, type_pi = "bootstrap", B=1000)
par(mfrow=c(1, 2))
plot(res, "TV.advert")
plot(res, "Quotes")
?replicate
library(ahead)
res <- ahead::basicf(fpp::insurance, h=10)
par(mfrow=c(1, 2))
plot(res, "TV.advert")
plot(res, "Quotes")
res <- ahead::basicf(fpp::insurance, method="rw", h=10)
par(mfrow=c(1, 2))
plot(res, "TV.advert")
plot(res, "Quotes")
res <- ahead::basicf(fpp::insurance, method="mean", h=10)
par(mfrow=c(1, 2))
plot(res, "TV.advert")
plot(res, "Quotes")
r optimize
optimize
?optimize
?nlminb
reticulate::repl_python()
pkgdown::build_site()
res$sims
res <- ahead::basicf(fpp::insurance, type_pi = "boostrap", B=5)
res <- ahead::basicf(fpp::insurance, type_pi = "bootstrap", B=5)
res$sims
res$mean
reticulate::repl_python()
bayesianoptimization::msnlminb
bayesianoptimization::random_search_opt
18*3
18*4
# https://dzone.com/articles/extend-python-datetime-workday
def workdayadd(start_date,work_days, whichdays=(MON,TUE,WED,THU,FRI)):
'''
Adds to a given date a number of working days
2009/12/04 for example is a friday - adding one weekday
will return 2209/12/07
>>> workdayadd(date(year=2009,month=12,day=4),1)
datetime.date(2009, 12, 7)
'''
weeks, days = divmod(work_days,len(whichdays))
new_date = start_date + timedelta(weeks=weeks)
for i in range(days):
while new_date.weekday() not in whichdays:
new_date += timedelta(days=1)
return new_date
reticulate::repl_python()
(pct_change_matrix <- matrix(rnorm(15), ncol = 3))
(w <- c(0.5, 0.4, 0.1))
pct_change_matrix*w
set.seed(100)
(pct_change_matrix <- matrix(rnorm(15), ncol = 3))
(w <- c(0.5, 0.4, 0.1))
(pct_change_matrix * t(replicate(5, w)))
pct_change_matrix*w
(pct_change_matrix * t(replicate(5, w)))
rowSums(pct_change_matrix * t(replicate(5, w)))
pct_change_matrix%*%w
w
pct_change_matrix%*%w
pct_change_matrix
pct_change_matrix[1, ]*w
sum(pct_change_matrix[1, ]*w)
sum(pct_change_matrix[2, ]*w)
sum(pct_change_matrix[3, ]*w)
sum(pct_change_matrix[4, ]*w)
sum(pct_change_matrix[5, ]*w)
pct_change_matrix%*%w
rowSums(pct_change_matrix * t(replicate(5, w)))
drop(pct_change_matrix%*%w)
all.equal(drop(pct_change_matrix%*%w), rowSums(pct_change_matrix * t(replicate(5, w))))
microbenchmark::microbenchmark(drop(pct_change_matrix%*%w), rowSums(pct_change_matrix * t(replicate(5, w))))
t(replicate(5, w))
all.equal(drop(pct_change_matrix%*%w), rowSums(pct_change_matrix * t(replicate(5, w))))
microbenchmark::microbenchmark(drop(pct_change_matrix%*%w), rowSums(pct_change_matrix * t(replicate(5, w))))
32329/1217
set.seed(100)
(pct_change_matrix <- matrix(rnorm(15), ncol = 3))
(w <- c(0.5, 0.4, 0.1))
drop(pct_change_matrix%*%w)
sum(pct_change_matrix[5, ]*w)
drop(pct_change_matrix%*%w
drop(pct_change_matrix%*%w)
drop(pct_change_matrix%*%w)
ret <- log(1 + RET)
RET <- drop(pct_change_matrix%*%w)
ret <- log(1 + RET)
ret
sum(ret)/sd(ret)
set.seed(100)
(pct_change_matrix <- matrix(rnorm(15), ncol = 3))
(w <- c(0.5, 0.4, 0.1))
(RET <- drop(pct_change_matrix%*%w))
(ret <- log(1 + RET))
sum(ret)/sd(ret)
pct_change_matrix
EuStockMarkets
?EuStockMarkets
EuStockMarkets[-1, ]/EuStockMarkets[-nrow(EuStockMarkets), ] - 1
matplot(EuStockMarkets[-1, ]/EuStockMarkets[-nrow(EuStockMarkets), ] - 1, type='l')
matplot(EuStockMarkets[-1, ]/EuStockMarkets[-nrow(EuStockMarkets), ] - 1, type='l')
matrix_returns <- EuStockMarkets[-1, ]/EuStockMarkets[-nrow(EuStockMarkets), ] - 1
objective <- function(w)
{
if (sum(w) == 0)
{
w <- w + 1e-2
}
w_ <- w/sum(w)
RET_t <- drop(matrix_returns%*%w_)
ret_t <- log(1 + RET_t)
return(-sum(ret_t)/sd(ret_t))
}
stats::nlminb(start = c(0.25, 0.25, 0.25, 0.25), objective = objective)
stats::nlminb(start = c(0.25, 0.25, 0.25, 0.25), objective = objective)
bayesianoptimization::msnlminb(objective = objective, nb_iter = 150,
lower = rep(-1, n_assets),
upper = rep(1, n_assets))
library(datasets)
library(bayesianoptimization)
matrix_returns <- EuStockMarkets[-1, ]/EuStockMarkets[-nrow(EuStockMarkets), ] - 1
n_assets <- ncol(EuStockMarkets)
objective <- function(w)
{
if (sum(w) == 0)
{
w <- w + 1e-2
}
w_ <- w/sum(w)
RET_t <- drop(matrix_returns%*%w_)
ret_t <- log(1 + RET_t)
return(-sum(ret_t)/sd(ret_t))
}
bayesianoptimization::msnlminb(objective = objective, nb_iter = 150,
lower = rep(-1, n_assets),
upper = rep(1, n_assets))
stats::nlminb(start = c(0.25, 0.25, 0.25, 0.25), objective = objective)
bayesianoptimization::msnlminb(objective = objective, nb_iter = 150,
lower = rep(-1, n_assets),
upper = rep(1, n_assets))
warnings()
bayesianoptimization::random_search_opt(objective = objective, nb_iter = 150,
lower = rep(-1, n_assets),
upper = rep(1, n_assets))
install.packages("DEoptim")
install.packages("DEoptim")
bayesianoptimization::random_search_opt(objective = objective, nb_iter = 150,
lower = rep(-1, n_assets),
upper = rep(1, n_assets))
bayesianoptimization::msnlminb(objective = objective, nb_iter = 150,
lower = rep(-1, n_assets),
upper = rep(1, n_assets))
warnings()
?try
objective <- function(w)
{
if (sum(w) == 0)
{
w <- w + 1e-2
}
w_ <- w/sum(w)
RET_t <- drop(matrix_returns%*%w_)
print(RET_t)
ret_t <- log(1 + RET_t)
return(-sum(ret_t)/sd(ret_t))
}
objective <- function(w)
{
if (sum(w) == 0)
{
w <- w + 1e-2
}
w_ <- w/sum(w)
RET_t <- drop(matrix_returns%*%w_)
print(RET_t)
ret_t <- log(1 + RET_t)
return(-sum(ret_t)/sd(ret_t))
}
stats::nlminb(start = c(0.25, 0.25, 0.25, 0.25), objective = objective)
bayesianoptimization::msnlminb(objective = objective, nb_iter = 150,
lower = rep(-1, n_assets),
upper = rep(1, n_assets))
warnings()
objective <- function(w)
{
if (sum(w) == 0)
{
w <- w + 1e-2
}
w_ <- w/sum(w)
RET_t <- drop(matrix_returns%*%w_)
ret_t <- try(log(1 + RET_t), silent = TRUE)
if (sum(is.na(ret_t)) > 0)
{
return
}
return(-sum(ret_t)/sd(ret_t))
}
stats::nlminb(start = c(0.25, 0.25, 0.25, 0.25), objective = objective)
objective <- function(w)
{
if (sum(w) == 0)
{
w <- w + 1e-2
}
w_ <- w/sum(w)
RET_t <- drop(matrix_returns%*%w_)
ret_t <- try(log(1 + RET_t), silent = TRUE)
if (sum(is.na(ret_t)) > 0)
{
return
}
return(-sum(ret_t)/sd(ret_t))
}
stats::nlminb(start = c(0.25, 0.25, 0.25, 0.25), objective = objective)
bayesianoptimization::msnlminb(objective = objective, nb_iter = 150,
lower = rep(-1, n_assets),
upper = rep(1, n_assets))
warnings()
?suppressWarnings
objective <- function(w)
{
if (sum(w) == 0)
{
w <- w + 1e-2
}
w_ <- w/sum(w)
RET_t <- drop(matrix_returns%*%w_)
ret_t <- suppressWarnings(log(1 + RET_t))
if (sum(is.na(ret_t)) > 0)
{
return (1e6)
}
return(-sum(ret_t)/sd(ret_t))
}
bayesianoptimization::msnlminb(objective = objective, nb_iter = 150,
lower = rep(-1, n_assets),
upper = rep(1, n_assets))
bayesianoptimization::random_search_opt(objective = objective, nb_iter = 150,
lower = rep(-1, n_assets),
upper = rep(1, n_assets))
DEoptim::DEoptim(fn = objective,
lower = rep(-1, n_assets),
upper = rep(1, n_assets))
?DEoptim::DEoptim
res1 <- stats::nlminb(start = c(0.25, 0.25, 0.25, 0.25), objective = objective)
res2 <- bayesianoptimization::msnlminb(objective = objective, nb_iter = 150,
lower = rep(-1, n_assets),
upper = rep(1, n_assets))
res3 <- bayesianoptimization::random_search_opt(objective = objective, nb_iter = 150,
lower = rep(-1, n_assets),
upper = rep(1, n_assets))
res4 <- DEoptim::DEoptim(fn = objective,
lower = rep(-1, n_assets),
upper = rep(1, n_assets))
res1$par
res1$objective
res2$par
res2$objective
res3$par
res3$objective
res3 <- bayesianoptimization::random_search_opt(objective = objective, nb_iter = 250,
lower = rep(-1, n_assets),
upper = rep(1, n_assets))
res3$objective
res4$membe
str(res4)
res3$par
res3$objective
res4$optim$bestmem
res4$optim$bestval
res1$par
res1$objective
res2$par
res2$objective
res3$par
res3$objective
res4$optim$bestmem
res4$optim$bestval
res1
res2
res3
res4
15/17-1
253+85
85/253+85
85/(253+85)
?any
X
X <- matrix(rnorm(15), ncol = 3)
X
rowSums(X) > 0
colSums(X) > 0
colSums(X) != 0
all(colSums(X) != 0)
X[,2] <- rep(0, 5)
X
all(colSums(X) != 0)
colSums(X) != 0
books
reticulate::repl_python()
